{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectinfo(data_dir='/data_remote/ABIDE/', file='Phenotypic'):\n",
    "    \"\"\"\n",
    "    :param file: csv file containing subject information\n",
    "    :return: dictionary with relevant key/value pairs\n",
    "    \"\"\"\n",
    "\n",
    "    COI_ABIDEI = ['SITE_ID', 'SUB_ID', 'DX_GROUP', 'AGE_AT_SCAN', 'SEX']\n",
    "    COI_ABIDEII = ['SITE_ID', 'SUB_ID', 'DX_GROUP', 'AGE_AT_SCAN ', 'SEX'] # Notice space after AGE_AT_SCAN\n",
    "\n",
    "    pheno_file = file + \"_ABIDE_I.csv\"\n",
    "    pheno_ABIDEI = pd.read_csv(osp.join(data_dir, pheno_file), \n",
    "                               dtype={'SITE_ID':str, 'SUB_ID':int, 'DX_GROUP':int, 'AGE_AT_SCAN':float, 'SEX':str})[COI_ABIDEI]\n",
    "    pheno_ABIDEI['ABIDE_I_or_II'] = pd.Series(np.ones(len(pheno_ABIDEI))).astype(int)\n",
    "\n",
    "    pheno_file = file + \"_ABIDE_II.csv\"\n",
    "    pheno_ABIDEII = pd.read_csv(osp.join(data_dir, pheno_file), encoding='cp1252',\n",
    "                               dtype={'SITE_ID':str, 'SUB_ID':int, 'DX_GROUP':int, 'AGE_AT_SCAN':float, 'SEX':int})[COI_ABIDEII]\n",
    "    pheno_ABIDEII['ABIDE_I_or_II'] = pd.Series(2*np.ones(len(pheno_ABIDEII))).astype(int)\n",
    "\n",
    "    pheno_ABIDEII.rename(columns = {'AGE_AT_SCAN ':'AGE_AT_SCAN'}, inplace=True) # change column name to take out stupid space   \n",
    "    \n",
    "    pheno = pd.concat([pheno_ABIDEI, pheno_ABIDEII], ignore_index=True)\n",
    "    pheno['DX_GROUP'] = pheno['DX_GROUP']-1 # so that 0-> ASD, 1->CON\n",
    "    \n",
    "    return pheno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file (Pandas Dataframe) for further machine learning\n",
    "\n",
    "def create_ml_csv(T1_file=None, \n",
    "                  nuisance_file='RS_denoise/nuisance_mat_18', \n",
    "                  img_file='RS_denoise/RS_clean_bptf_MNI.nii.gz',\n",
    "                  input_root_dir='/data_local/deeplearning/ABIDE_LC',\n",
    "                  output_root_dir='/data_local/deeplearning/ABIDE_ML_inputs',\n",
    "                  time_course_dir = 'tc',\n",
    "                  subject_list_file='list_2169'):\n",
    "    \n",
    "    '''\n",
    "    subject_list_file: a file with a list of subject ids\n",
    "    root_dir: root directory with imaging and nuisance data\n",
    "    img_file: rsfmri file\n",
    "    T1_file: T1 scan file\n",
    "    nuisance_file: confounds (motion etc.,)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    subject_list = pd.read_csv(osp.join(input_root_dir, subject_list_file), names=['SUB_ID'], header=None)\n",
    "    subject_info = get_subjectinfo()\n",
    "    \n",
    "    df_data_info = subject_info.merge(subject_list, on='SUB_ID')\n",
    "    df_data_info['SUB_ID'] = np.loadtxt(osp.join(input_root_dir, subject_list_file), dtype='str') # easier to get '00' prefix\n",
    "    #data_columns = ['ids', 'labels', 'tr', 'rsfmri', 't1', 'nuisance']\n",
    "    \n",
    "    rsfmri_file_list = []\n",
    "    nuisance_file_list = []\n",
    "    TR_list = []\n",
    "    nT_list = []\n",
    "    \n",
    "    #outputs\n",
    "    tc_file_list = [] # time course filenames\n",
    "    ccvec_file_list = [] # correlation matrix filenames\n",
    "    ccmat_file_list = [] # correlation matrix filenames\n",
    "    \n",
    "    # Check if output directory exists\n",
    "    if not osp.exists(output_root_dir):\n",
    "        os.makedirs(output_root_dir)\n",
    "        \n",
    "    \n",
    "    for sub_i in df_data_info['SUB_ID']:\n",
    "        rsfmri_file = osp.join(input_root_dir, 'raw', sub_i, img_file)\n",
    "        \n",
    "        hdr = nib.load(rsfmri_file).header\n",
    "        \n",
    "        TR_list.append(hdr.get_zooms()[3])\n",
    "        nT_list.append(hdr.get_data_shape()[3])\n",
    "        rsfmri_file_list.append(rsfmri_file)\n",
    "        nuisance_file_list.append(osp.join(input_root_dir, 'raw', sub_i, nuisance_file))\n",
    "        \n",
    "        #outputs ATLAS->generic name that is a placeholder\n",
    "        tc_file_list.append(osp.join(output_root_dir, sub_i, time_course_dir, 'ATLAS/timecourse.csv'))\n",
    "        ccvec_file_list.append(osp.join(output_root_dir, sub_i, time_course_dir, 'ATLAS/corr_vec.npy'))\n",
    "        ccmat_file_list.append(osp.join(output_root_dir, sub_i, time_course_dir, 'ATLAS/corr_mat.npy'))\n",
    "\n",
    "\n",
    "    df_data_info['RSFMRI_file'] = rsfmri_file_list\n",
    "    df_data_info['TR'] = TR_list\n",
    "    df_data_info['nTimes'] = nT_list\n",
    "    df_data_info['nuisance_file'] = nuisance_file_list\n",
    "    \n",
    "    df_data_info['tc_file'] = tc_file_list\n",
    "    df_data_info['corrvec_file'] = ccvec_file_list\n",
    "    df_data_info['corrmat_file'] = ccmat_file_list\n",
    "    \n",
    "    return df_data_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_IC_files(atlas_name, atlas_dir='/data/rmthomas/nilearn_data/IC_JAMA'): # HO_cort_maxprob_thr25-2mm\n",
    "\n",
    "    # Choose one of the atlases (add more when necessary)\n",
    "    # 1. AAL\n",
    "    # 2. HO_cort_maxprob_thr25-2mm\n",
    "\n",
    "\n",
    "    # Check if valid atlas name\n",
    "    if atlas_name not in ['JAMA_IC19', 'JAMA_IC52', 'JAMA_IC7']:\n",
    "        raise ValueError('atlas_name not found')\n",
    "\n",
    "    if atlas_name == 'JAMA_IC19':\n",
    "        IC_dir = osp.join(atlas_dir, atlas_name)\n",
    "        IC_file = osp.join(atlas_dir, 'IC19.nii')\n",
    "        nrois = 19\n",
    "    \n",
    "    if atlas_name == 'JAMA_IC52':\n",
    "        IC_dir = osp.join(atlas_dir, atlas_name)\n",
    "        IC_file = osp.join(atlas_dir, 'IC52.nii')\n",
    "        nrois = 52\n",
    "    \n",
    "    if atlas_name == 'JAMA_IC7':\n",
    "        IC_dir = osp.join(atlas_dir, atlas_name)\n",
    "        IC_file = osp.join(atlas_dir, 'IC7.nii')\n",
    "        nrois = 7\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_atlas(atlas_name, atlas_dir='/data/rmthomas/nilearn_data'): # HO_cort_maxprob_thr25-2mm\n",
    "\n",
    "    # Choose one of the atlases (add more when necessary)\n",
    "    # 1. AAL\n",
    "    # 2. HO_cort_maxprob_thr25-2mm\n",
    "\n",
    "\n",
    "    # Check if valid atlas name\n",
    "    if atlas_name not in ['JAMA_IC19', 'JAMA_IC52', 'JAMA_IC7']:\n",
    "        raise ValueError('atlas_name not found')\n",
    "\n",
    "    if atlas_name == 'JAMA_IC19':\n",
    "        atlas_filename = osp.join(atlas_dir, 'IC_JAMA/IC19.nii')\n",
    "        labels =[1]\n",
    "    \n",
    "    if atlas_name == 'JAMA_IC52':\n",
    "        atlas_filename = osp.join(atlas_dir, 'IC_JAMA/IC52.nii')\n",
    "        labels =[1]\n",
    "        \n",
    "    if atlas_name == 'JAMA_IC7':\n",
    "        atlas_filename = osp.join(atlas_dir, 'IC_JAMA/IC7.nii')\n",
    "        labels =[1]\n",
    "        \n",
    "    return  atlas_filename, labels, len(labels)\n",
    "    #plotting.plot_roi(atlas_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass(atlas_filename, to_bandpass = False, tr=1.0, low_freq=0.01, high_freq=0.001):\n",
    "    if to_bandpass:\n",
    "        masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True, t_r=tr, low_pass=low_freq, high_pass=high_freq)\n",
    "    else:\n",
    "        masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True)\n",
    "        \n",
    "    return masker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "xx=nib.load('/data/rmthomas/nilearn_data/IC_JAMA/IC7.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 109, 91, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created in /data/rmthomas/nilearn_data/msdl_atlas\n",
      "\n",
      "Downloading data from https://team.inria.fr/parietal/files/2015/01/MSDL_rois.zip ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloaded 209734 of 209734 bytes (100.0%,    0.0s remaining) ...done. (0 seconds, 0 min)\n",
      "Extracting data from /data/rmthomas/nilearn_data/msdl_atlas/5d25e157f36214b8ca9a12fd417aac1c/MSDL_rois.zip..... done.\n"
     ]
    }
   ],
   "source": [
    "atlas = datasets.fetch_atlas_msdl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 48, 35, 39)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = nib.load(atlas['maps'])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tc_corr(atlas_names=['AAL', 'schaefer_100', 'HO_cort_maxprob_thr25-2mm', 'schaefer_400'],\n",
    "                    output_root_dir='/data_local/deeplearning/ABIDE_ML_inputs',\n",
    "                    time_course_dir = 'tc',\n",
    "                    to_bandpass=False):\n",
    "\n",
    "    \n",
    "    df_data_info = create_ml_csv()\n",
    "    \n",
    "    # Write the generic input and output csv files\n",
    "    df_data_info.to_csv(osp.join(output_root_dir, 'data_info.csv'))\n",
    "    \n",
    "    \n",
    "    connectivity_measure = ConnectivityMeasure(kind='correlation')\n",
    "\n",
    "    \n",
    "    nsubjects = len(df_data_info)\n",
    "    \n",
    "    print_counter = 0\n",
    "    for sub_i in df_data_info.index:\n",
    "\n",
    "        \n",
    "        if print_counter%100 == 0:\n",
    "            print(f'{sub_i}/{nsubjects}')\n",
    "        nuisance = pd.read_csv(df_data_info['nuisance_file'].loc[sub_i], sep='\\t', header=None)\n",
    "        nuisance.to_csv('temp_nuisance.csv') # required for the next step in csv format\n",
    "\n",
    "        for atlas_name in atlas_names:\n",
    "            \n",
    "            atlas_filename, labels, nrois = select_atlas(atlas_name)\n",
    "            \n",
    "            \n",
    "            if to_bandpass:\n",
    "                    masker = bandpass(atlas_filename, to_bandpass=to_bandpass, tr=df_data_info['TR'].loc[sub_i])\n",
    "            else:\n",
    "                    masker = bandpass(atlas_filename, to_bandpass=to_bandpass)\n",
    "\n",
    "            timecourse = masker.fit_transform(imgs=df_data_info['RSFMRI_file'].loc[sub_i]) \n",
    "                                              #confounds='temp_nuisance.csv')\n",
    "\n",
    "\n",
    "            cc = connectivity_measure.fit_transform([timecourse])[0]\n",
    "\n",
    "            tc_dir = osp.join(output_root_dir, df_data_info['SUB_ID'].loc[sub_i], \n",
    "                              time_course_dir, atlas_name )\n",
    "            if not osp.exists(tc_dir):\n",
    "                os.makedirs(tc_dir)\n",
    "\n",
    "            # Write timeseries as csv file\n",
    "            tc_file = df_data_info['tc_file'].loc[sub_i].replace('ATLAS', atlas_name)\n",
    "            pd.DataFrame(data=timecourse, columns=labels).to_csv(tc_file, index=False)\n",
    "\n",
    "            # Write correlation matrix\n",
    "            corrvec_file = df_data_info['corrvec_file'].loc[sub_i].replace('ATLAS', atlas_name)\n",
    "            corrmat_file = df_data_info['corrmat_file'].loc[sub_i].replace('ATLAS', atlas_name)\n",
    "            cc_triu_ids = np.triu_indices(nrois)\n",
    "            \n",
    "            np.save(corrvec_file, cc[cc_triu_ids]) # get only upper triangular\n",
    "            np.save(corrmat_file, cc)\n",
    "            \n",
    "            \n",
    "            \n",
    "        print_counter += 1\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \n",
    "    atlas_names=['AAL', 'schaefer_100', 'HO_cort_maxprob_thr25-2mm', 'schaefer_400']\n",
    "    output_root_dir='/data_local/deeplearning/ABIDE_ML_inputs'\n",
    "    time_course_dir = 'tc'\n",
    "    \n",
    "    extract_tc_corr(atlas_names=atlas_names, output_root_dir=output_root_dir, time_course_dir=time_course_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2169\n",
      "100/2169\n",
      "200/2169\n",
      "300/2169\n",
      "400/2169\n",
      "500/2169\n",
      "600/2169\n",
      "700/2169\n",
      "800/2169\n",
      "900/2169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-dd6b657f9832>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtime_course_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mextract_tc_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matlas_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matlas_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_root_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_root_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_course_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_course_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4bb888d32892>\u001b[0m in \u001b[0;36mextract_tc_corr\u001b[0;34m(atlas_names, output_root_dir, time_course_dir, to_bandpass)\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mmasker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbandpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matlas_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_bandpass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_bandpass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtimecourse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_data_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RSFMRI_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                                               \u001b[0;31m#confounds='temp_nuisance.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/nilearn/input_data/nifti_labels_masker.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, imgs, confounds)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\" Prepare and perform signal extraction from regions.\n\u001b[1;32m    196\u001b[0m         \"\"\"\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, imgs, confounds)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_single_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/nilearn/input_data/nifti_labels_masker.py\u001b[0m in \u001b[0;36mtransform_single_imgs\u001b[0;34m(self, imgs, confounds)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mmemory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             verbose=self.verbose)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36mfilter_and_extract\u001b[0;34m(imgs, extraction_function, parameters, memory_level, memory, verbose, confounds, copy, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m     region_signals, aux = cache(extraction_function, memory,\n\u001b[1;32m     99\u001b[0m                                 \u001b[0mfunc_memory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                                 memory_level=memory_level)(imgs)\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# Temporal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/nilearn/input_data/nifti_labels_masker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         return signal_extraction.img_to_signals_labels(\n\u001b[1;32m     30\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resampled_labels_img_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             background_label=self.background_label)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/nilearn/regions/signal_extraction.py\u001b[0m in \u001b[0;36mimg_to_signals_labels\u001b[0;34m(imgs, labels_img, mask_img, background_label, order)\u001b[0m\n\u001b[1;32m    107\u001b[0m         signals[n] = np.asarray(ndimage.measurements.mean(img,\n\u001b[1;32m    108\u001b[0m                                                           \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                                                           index=labels))\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Set to zero signals for missing labels. Workaround for Scipy behaviour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mmissing_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/scipy/ndimage/measurements.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(input, labels, index)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \"\"\"\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/scipy/ndimage/measurements.py\u001b[0m in \u001b[0;36m_stats\u001b[0;34m(input, labels, index, centered)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# be 1-d, but it should be interpreted as the flattened n-d array of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# label indices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0munique_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0msums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid axis kwarg specified for unique'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0miflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0minv_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0minv_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m     \"\"\"\n\u001b[0;32m-> 2165\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cumsum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fd6738c0c18>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAJOCAYAAAD27eW+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOAAAgE4IcAAAAJ34/wEvYRvIC0USeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd673705048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data exploration\n",
    "\n",
    "df = create_ml_csv()\n",
    "# plot ntimes to check what to include\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,10))\n",
    "df.hist(column='nTimes', bins=[50, 100, 125, 150, 200, 300, 500, 1000], ax=axes[0])\n",
    "df.hist(column='nTimes', cumulative=-1, bins=[50, 100, 125, 150, 200, 300, 1000], linewidth=5, histtype='step', ax=axes[1])\n",
    "#df_input_data['nTimes'].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=datasets.fetch_atlas_aal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=datasets.fetch_atlas_harvard_oxford(atlas_name='cort-maxprob-thr25-2mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xx.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
